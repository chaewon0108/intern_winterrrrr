import os
import cv2
import pandas as pd
import numpy as np
from tqdm import tqdm
import torch
from src.faceinsight.engine.chain.val_aro_image_chain import ValenceArousalImageChain

def run_folder_analysis_pyfeat(image_base_path, chain, emotion_classes, save_faces=False, output_face_dir=None):
    """
    PyFeatìœ¼ë¡œ ê°ì • ë¶„ì„ + ê²€ì¶œëœ ì–¼êµ´ ì €ì¥
    
    Args:
        image_base_path: ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        chain: ValenceArousalImageChain ê°ì²´
        emotion_classes: ê°ì • í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
        save_faces: ê²€ì¶œëœ ì–¼êµ´ ì €ì¥ ì—¬ë¶€
        output_face_dir: ì–¼êµ´ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    valid_extensions = {".jpg", ".jpeg", ".png", ".bmp"}
    if not os.path.exists(image_base_path):
        print(f"ê²½ë¡œ ì—†ìŒ: {image_base_path}")
        return pd.DataFrame()

    image_files = [f for f in os.listdir(image_base_path) if os.path.splitext(f)[1].lower() in valid_extensions]
    image_files.sort() 

    print(f"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ Py-Feat ì—”ì§„ìœ¼ë¡œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ì–¼êµ´ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    if save_faces and output_face_dir:
        os.makedirs(output_face_dir, exist_ok=True)
        print(f"ê²€ì¶œëœ ì–¼êµ´ ì €ì¥ ê²½ë¡œ: {output_face_dir}")

    output_label_map = { 
        0: 'esti_angry', 1: 'esti_disgust', 2: 'esti_fear', 3: 'esti_happy', 
        4: 'esti_sad', 5: 'esti_surprise', 6: 'esti_neutral'
    }

    results_data = []
    total_saved_faces = 0
    miss_count = 0  # miss ì¹´ìš´íŠ¸

    for filename in tqdm(image_files, desc="Analyzing Py-Feat"):
        img_full_path = os.path.join(image_base_path, filename)
        input_image = cv2.imread(img_full_path)

        analysis_res = {
            "filename": filename, 
            "is_detected": False,
            "count_faces": 0,
            
            "confidence": 0.0, 

            "esti_expression": "unknown",  # ëŒ€í‘œ(1ë“±) ê°ì •
            "esti_score": 0.0,  # ëŒ€í‘œ ê°ì •ì˜ í™•ë¥ ê°’ (emotion probability)

            "esti_angry": 0.0, "esti_disgust": 0.0, "esti_fear": 0.0,
            "esti_happy": 0.0, "esti_sad": 0.0, "esti_surprise": 0.0, "esti_neutral": 0.0,
            
            "cage_valence": 0.0,
            "cage_arousal": 0.0,
        }

        if input_image is not None:
            h, w = input_image.shape[:2]
            image_rgb = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
            
            _, _, faces, _, emotions, _ = chain.au_agent.run(image_rgb, ndarray_to_list=False)

            if faces is not None and len(faces) > 0:
                actual_faces = faces[0] if len(faces) > 0 else []
                
                valid_faces = []
                if isinstance(actual_faces, (list, np.ndarray)) and len(actual_faces) > 0:
                    for face in actual_faces:
                        if isinstance(face, (list, np.ndarray)) and len(face) >= 5:
                            valid_faces.append(face)
                
                if len(valid_faces) > 0:
                    analysis_res["is_detected"] = True
                    analysis_res["count_faces"] = len(valid_faces)
                    
                    first_face = valid_faces[0]
                    if len(first_face) >= 5:
                        analysis_res["confidence"] = round(float(first_face[4]), 3)
                    
                    # â˜… ê²€ì¶œëœ ì–¼êµ´ë“¤ ì €ì¥ â˜…
                    if save_faces and output_face_dir:
                        base_filename = os.path.splitext(filename)[0]
                        
                        for face_idx, face in enumerate(valid_faces):
                            x1, y1, x2, y2 = int(face[0]), int(face[1]), int(face[2]), int(face[3])
                            
                            # ì´ë¯¸ì§€ ë²”ìœ„ ì²´í¬
                            x1 = max(0, x1)
                            y1 = max(0, y1)
                            x2 = min(w, x2)
                            y2 = min(h, y2)
                            
                            # ì–¼êµ´ ì˜ì—­ ì˜ë¼ë‚´ê¸°
                            face_crop = input_image[y1:y2, x1:x2]
                            
                            if face_crop.size > 0:
                                face_filename = f"{base_filename}_face{face_idx}.jpg"
                                face_filepath = os.path.join(output_face_dir, face_filename)
                                cv2.imwrite(face_filepath, face_crop)
                                total_saved_faces += 1
                
                    # face[0]ì„ ê¸°ì¤€ìœ¼ë¡œ ê°ì • ë¶„ì„
                    if emotions is not None and len(emotions) > 0:
                        probs = emotions
                        while isinstance(probs, (list, np.ndarray)) and len(probs) > 0 and isinstance(probs[0], (list, np.ndarray)):
                            probs = probs[0]
                        
                        if isinstance(probs, (list, np.ndarray)) and len(probs) > 0:
                            dom_idx = np.argmax(probs)
                            dom_score = probs[dom_idx]
                            
                            analysis_res["esti_score"] = round(float(dom_score), 3)
                            
                            # socre < 0.5ë©´ miss ì²˜ë¦¬í•˜ë ¤ê³  í–ˆê¸”
                            if dom_score < 0.5:
                                analysis_res["esti_expression"] = "miss"
                                # ê·¸ë˜í”„ì— ë°˜ì˜ë˜ì§€ ì•Šë„ë¡ is_detectedë¥¼ Falseë¡œ ì„¤ì •
                                analysis_res["is_detected"] = False
                                miss_count += 1
                            else:
                                analysis_res["esti_expression"] = emotion_classes[dom_idx]

                            # ëª¨ë“  ê°ì • í™•ë¥ ì€ ì €ì¥ (ë¶„ì„ìš©)
                            for idx, key in output_label_map.items():
                                analysis_res[key] = round(float(probs[idx]), 3)
                    
                    # â˜…â˜…â˜… CAGE ëª¨ë¸ë¡œ valence/arousal ê³„ì‚° â˜…â˜…â˜…
                    # miss ì²˜ë¦¬ëœ ê²½ìš°ì—ë„ CAGEëŠ” ê³„ì‚° (ë¶„ì„ìš©)
                    if chain.use_cage and analysis_res["esti_expression"] != "miss":
                        try:
                            with torch.no_grad():
                                x1, y1, x2, y2, _ = first_face[:5]
                                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                                
                                face_crop = input_image[y1:y2, x1:x2]
                                
                                if face_crop.size > 0:
                                    face_crop_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)
                                    
                                    cage_input = chain.cage_transformer(face_crop_rgb)
                                    cage_input = cage_input.unsqueeze(0).to(chain.cage_device)
                                    
                                    cage_output = chain.cage(cage_input)
                                    cage_output_tensor = cage_output.squeeze(0)
                                    cage_output_np = cage_output_tensor.cpu().numpy()
                                    
                                    if len(cage_output_np) >= 9:
                                        cage_valence = float(cage_output_np[7])
                                        cage_arousal = float(cage_output_np[8])
                                        
                                        analysis_res["cage_valence"] = round(cage_valence, 3)
                                        analysis_res["cage_arousal"] = round(cage_arousal, 3)
                        except Exception as e:
                            print(f"  âš ï¸ CAGE ì²˜ë¦¬ ì˜¤ë¥˜ ({filename}): {e}")
                            analysis_res["cage_valence"] = 0.0
                            analysis_res["cage_arousal"] = 0.0

        results_data.append(analysis_res)
    
    if save_faces:
        print(f"\nâœ… ì´ {total_saved_faces}ê°œì˜ ì–¼êµ´ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print(f"\nğŸ“Š í†µê³„:")
    print(f"  - ì´ í”„ë ˆì„: {len(image_files)}")
    print(f"  - Miss (score < 0.5): {miss_count}ê°œ")
    print(f"  - ìœ íš¨ ê°ì •: {len(image_files) - miss_count}ê°œ")

    return pd.DataFrame(results_data)

if __name__ == "__main__":
    IMAGE_BASE_PATH = "/home/technonia/intern/faceinsight/0127/0127_dmaps_sample_video_img/3ì‹ ë‚¨ìœ ì§„_img/19-19191919_deep-question/"
    OUTPUT_CSV_PATH = "/home/technonia/intern/faceinsight/0128/0128_youtube_dmaps_graph/test/test_csv/0128_test_ì‹ ë‚¨ìœ ì§„_deep-question.csv"
    SAVE_FACES = False
    OUTPUT_FACE_DIR = ""

    chain = ValenceArousalImageChain(cage_model_name="model.pt", cage_device="cpu")
    emotion_classes = chain.au_agent.emotion_labels

    if os.path.exists(IMAGE_BASE_PATH):
        df_final = run_folder_analysis_pyfeat(
            IMAGE_BASE_PATH, 
            chain, 
            emotion_classes,
            save_faces=SAVE_FACES,
            output_face_dir=OUTPUT_FACE_DIR
        )
        
        df_final.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')
        
        print("\n" + "="*50)
        print(f"Py-Feat ë¶„ì„ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: {OUTPUT_CSV_PATH}")
        if SAVE_FACES:
            print(f"\nì–¼êµ´ ì €ì¥ ê²½ë¡œ: {OUTPUT_FACE_DIR}")
        print("="*50)
    else:
        print(f"ê²½ë¡œ ì˜¤ë¥˜: {IMAGE_BASE_PATH}")

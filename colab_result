import torch
import torch.nn as nn
from torchvision import transforms, models
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import pandas as pd
import numpy as np
import os
from tqdm import tqdm

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

MODEL_PATH = "/home/technonia/intern/faceinsight/models/cage/model.pt"
INPUT_CSV_PATH = "/home/technonia/intern/faceinsight/validation_0113.csv"
#"/home/technonia/intern/faceinsight/close/validation_close_img_0115_update.csv"
# /home/technonia/intern/faceinsight/validation_0113.csv
BASE_IMAGE_FOLDER = "/home/technonia/intern/faceinsight/validation_csv_img"
# close/close_img_0115"
OUTPUT_CSV_PATH = "0120_colab_affectnet_all_img_result.csv"
BATCH_SIZE = 128 #colab이랑 똑같이 맞춰서 돌림

print("batch size : " ,BATCH_SIZE)

EMOTIONS = {0: 'neutral', 1: 'happy', 2: 'sad', 3: 'surprise', 4: 'fear', 5: 'disgust', 6: 'angry'}

def load_trained_model(model_path):    
    if not os.path.exists(model_path):
        print(f"모델 파일 없음: {model_path}")
        return None
        
    checkpoint = torch.load(model_path, map_location=DEVICE)
    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint

    try:
        model = models.maxvit_t(weights="DEFAULT") #colab이랑 똑같
    except Exception as e:
        print(f"model load 할 때 에러: {e}")
        return None

    in_features = model.classifier[5].in_features
    model.classifier[5] = nn.Linear(in_features, 9, bias=False)
    
    new_state_dict = {}
    for k, v in state_dict.items():
        new_k = k
        if 'head.fc.' in k:
            new_k = k.replace('head.fc.', 'classifier.5.')
        elif 'head.' in k:
            new_k = k.replace('head.', 'classifier.5.')
        new_state_dict[new_k] = v

    msg = model.load_state_dict(new_state_dict, strict=True)
    print(f"load 결과: {msg}") #다 성공

    model.to(DEVICE)
    model.eval()
    return model

class AffectNetDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.df = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        
        label_mapping = {'anger': 'angry', 'happiness': 'happy'} # csv 확인하기 (완)
        if 'expression' in self.df.columns:
            self.df['expression'] = self.df['expression'].replace(label_mapping)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_name = self.df.iloc[idx]['filename']
        img_path = os.path.join(self.root_dir, img_name)
        
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, 1 
        except Exception:
            return torch.zeros((3, 224, 224)), 0


def run_inference():
    model = load_trained_model(MODEL_PATH)
    if model is None: return

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), #colab이랑 동일
    ])

    dataset = AffectNetDataset(INPUT_CSV_PATH, BASE_IMAGE_FOLDER, transform=transform)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

    print(f"데이터 :: {len(dataset)}개")
    all_probs = []
    all_va = []

    with torch.no_grad():
        for images, valids in tqdm(dataloader):
            images = images.to(DEVICE)
            outputs = model(images)

            if outputs.shape[1] == 9:
                outputs_cls = outputs[:, :7] #감정 7개
                outputs_reg = outputs[:, 7:] #valence, arousal 2개
            else:
                outputs_cls = outputs
                outputs_reg = torch.zeros(outputs.size(0), 2).to(DEVICE)

            probs = torch.nn.functional.softmax(outputs_cls, dim=1)
            all_probs.append(probs.cpu().numpy())
            all_va.append(outputs_reg.cpu().numpy())

    final_probs = np.concatenate(all_probs, axis=0) 
    final_va = np.concatenate(all_va, axis=0)
    df = dataset.df
    top_indices = np.argmax(final_probs, axis=1)
    
    df['esti_expression'] = [EMOTIONS[idx] for idx in top_indices] #최종 감정
    df['esti_score'] = np.round(np.max(final_probs, axis=1), 3) #최종 감정의 점수

    df['esti_valence'] = np.round(final_va[:, 0], 3)
    df['esti_arousal'] = np.round(final_va[:, 1], 3)

    emotion_cols = ['esti_neutral', 'esti_happy', 'esti_sad', 'esti_surprise', 'esti_fear', 'esti_disgust', 'esti_anger']
    for i, col in enumerate(emotion_cols):
        df[col] = np.round(final_probs[:, i], 3)

    df.to_csv(OUTPUT_CSV_PATH, index=False)
    print(f"\n완료!: {OUTPUT_CSV_PATH}")

if __name__ == "__main__":
    run_inference()
